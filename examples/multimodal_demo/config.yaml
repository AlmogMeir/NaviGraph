log_level: info
experiment_path: .
experiment_output_path: "{PROJECT_ROOT}/output"

# Setup configuration (used by setup commands)
setup:
  map_path: ./resources/maze_map.png
  spatial_image_for_calibration: ./demo_session/memory5-11022023_withrewardafter8min.avi
  calibration_matrix: ./resources/transform_matrix.npy

plugins:
  # Primary pose estimation data (establishes temporal index)
  - name: pose_data
    type: pose_tracking
    file_pattern: '.*DLC.*\.h5$'  # Match DeepLabCut H5 files
    config:
      bodypart: 'Nose'
      likelihood_threshold: 0.3
      bodyparts: 'all'

  # Camera calibration transformation matrix
  - name: calibration_matrix
    type: calibration
    shared: true  # Look in resources folder
    file_pattern: 'transform_matrix\.npy$'
    config: {}

  # Neural activity from calcium imaging
  - name: neural_activity
    type: neural_activity
    file_pattern: '^minian$'  # Match minian folder exactly
    config:
      components: null  # Extract all components (C, S, A). Set to ['C', 'S'] to exclude contours
      neurons: null     # Extract all neurons. Set to [3, 4, 5] to select specific neurons
      derived_metrics:
        neuron_mean_activity: 'mean'  # Calculate mean activity across all C traces
    

  # Head direction from IMU sensor
  - name: head_direction
    type: head_direction
    file_pattern: '.*headOrientation\.csv$'  # Match head orientation CSV
    config:
      yaw_offset: -167  # Calibration offset for yaw angle (degrees)
      positive_direction: -1  # Direction correction multiplier
      skip_index: 2  # Sampling rate adjustment (use every nth sample)
      merge_mode: "left"  # Merge strategy with session DataFrame

  # Spatial coordinate transformation and tile detection
  - name: map_coords
    type: map_location
    shared: true  # Map is shared across sessions
    file_pattern: '.*maze_map\.png$'  # Match maze map image
    config:
      bodyparts: ['Nose']  # Which bodyparts to track for map coordinates

  # Graph-based spatial navigation analysis
  - name: graph_coords
    type: graph_location
    shared: true  # Graph is shared across sessions
    config:
      reward_tile_id: 273  # Tile ID for reward location

graph:
  builder:
    type: binary_tree
    config:
      height: 7
  mapping_file: ./resources/complex_maze_graph_mapping.pkl
  conflict_strategy: node_priority

analyze:
  metrics:
    time_to_reward: 
      func_name: 'time_a_to_b'
      args: 
        a: 145
        b: 273
    
    velocity_to_reward:
      func_name: 'velocity_a_to_b'
      args:
        a: 145
        b: 273
    
    exploration_percentage:
      func_name: 'exploration_percentage'

  save_as_csv: true
  save_as_pkl: true
  save_raw_data_as_pkl: true

# Visualization configuration (used when running with visualize mode)
visualizations:
  output:
    enabled: true
    format: mp4
    fps: 30
    codec: mp4v
    
  pipeline:
    # First panel (left): Spatial navigation video with pose tracking
    - name: bodypart_display
      type: bodyparts
      config:
        bodyparts: ['Nose']  # Focus on nose for cleaner view
        colors:
          Nose: [0, 0, 255]      # Red
        radius: 6
        show_labels: false
        likelihood_threshold: 0.8

    # Second panel (middle): Neural activity video with contour segmentation
    - name: neural_segmentation_display
      type: neural_segmentation
      config:
        mode: 'side_by_side'      # Add neural video to the right of spatial video
        panel_width: 'auto'       # Auto-calculate width to match height
        columns: null             # Show all neuron contours

        # Activity-based filtering for dynamic visualization
        # activity_threshold: 0.1   # Only show neurons with activity > 0.1
        # normalize_activity: False  # Normalize activity values for visualization
        # modulate_opacity: true    # Vary contour brightness based on activity
        # modulate_color: false     # Keep consistent colors
        # max_neurons_per_frame: 15 # Limit for performance (top 15 most active)

        # Contour visualization - optimized for performance
        contour_thickness: 2
        contour_fill: false       # PERFORMANCE: Use hollow contours (faster)
        fill_opacity: 0.3         # Lower opacity for better performance

        # Contour optimization settings
        # simplify_contours: true   # Use Douglas-Peucker simplification
        # simplification_epsilon: 1.5  # Balance between accuracy and performance
        # downsample_contours: true # Skip every nth contour point
        # downsample_factor: 2      # Use every 2nd point

        # Label settings - optimized
        show_labels: true
        show_activity_values: false  # Keep false for performance
        label_font_scale: 0.5
        label_position: 'centroid'
        label_offset: [3, -3]     # Slightly smaller offset
        label_background: false   # Remove background for performance

        # Color scheme
        color_scheme: 'auto'      # Auto-generate distinct colors

    # Third panel (right): Time series of neural activity
    - name: neural_time_series
      type: time_series
      config:
        # Data to plot - examples showing different neural data types
        columns: ['unit_id_94_C', 'unit_id_76_C', 'neuron_mean_activity']  # C (calcium), S (spikes), and mean

        # Display settings for side-by-side layout
        mode: 'side_by_side'      # Add time series to the right
        panel_width: 400          # Fixed width for time series panel

        # Time series behavior
        plot_mode: 'fixed_window'
        window_size: 200          # Show last 200 frames (~6.7 seconds at 30fps)

        # Y-axis range control
        y_range_mode: 'fixed'
        y_range: [0, 5]

        # Visual styling
        figure_size: [6, 4]       # Adjusted for side panel
        dpi: 100
        background_color: 'black'
        grid_color: '#004400'
        grid_alpha: 0.3

        # Line styling - different colors for each trace
        colors: ['#00ff00', '#ff00ff', '#00ffff']  # Green (C), Magenta (S), Cyan (mean)
        line_width: 2.0

        # Axes and labels - optimized for side-by-side concatenation
        show_axes: false           # Show axes for side panel
        show_y_ticks: false       # Remove y-axis ticks for cleaner look
        label_position: 'right'   # Move labels to right side for concatenation
        show_labels: true         # Show labels for clarity
        show_values: true
        font_size: 7

        # Performance
        update_interval: 1

    # Additional info overlay on the combined view
    - name: multimodal_info
      type: text_display
      config:
        columns: ['Nose_graph_node', 'yaw']
        position: 'top_left'      # Overlay on the combined three-panel view
        font_scale: 0.7
        color: [255, 255, 255]
        background: true
        background_opacity: 0.7
        decimal_places: 0

        # Display formatting options
        show_column_names: true
        layout: 'vertical'
        separator: ' | '

# Expected file structure:
# demo_session/
# ├── memory5-11022023_withrewardafter8min.avi                    # Video file
# ├── memory5-11022023_withrewardafter8minDLC_...h5              # DeepLabCut keypoints
# ├── headOrientation.csv                                         # Head direction (qw,qx,qy,qz)
# └── minian/                                                     # Neural data directory
#     ├── A.zarr/                                                # Spatial footprints
#     ├── C.zarr/                                                # Calcium traces (df/f)
#     ├── S.zarr/                                                # Smoothed traces
#     └── ... (other Minian outputs)

# Notes:
# 1. This configuration creates a three-panel side-by-side visualization:
#    - Left panel: Spatial navigation video with pose tracking (red nose marker)
#    - Middle panel: Neural activity video with DYNAMIC neuron contour overlays
#    - Right panel: Real-time time series plots of neural activity
# 2. Neural activity data will be available as columns:
#    - unit_id_3_C, unit_id_4_C, ... (calcium traces for each neuron)
#    - unit_id_3_S, unit_id_4_S, ... (spike activity for each neuron)
#    - unit_id_3_A_contour, ... (activity-modulated contours for each neuron)
#    - neuron_mean_activity (mean of all calcium traces)
# 3. Head direction data will be available as columns: yaw, pitch, roll
# 4. All data is synchronized by frame index for temporal alignment
# 5. The session DataFrame will contain all modalities for comprehensive analysis
# 6. Neural video (if found) is provided as 'neural_video' in shared resources
# 7. DYNAMIC VISUALIZATION: Contours appear/disappear based on neural activity
# 8. Only active neurons (activity > threshold) are shown per frame
# 9. Contour brightness varies with activity level for biological accuracy
# 10. Performance optimized: single overlay rendering, activity-based filtering